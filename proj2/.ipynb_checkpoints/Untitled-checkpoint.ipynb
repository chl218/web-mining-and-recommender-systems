{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from urllib.request import urlopen\n",
    "import scipy.optimize\n",
    "import random\n",
    "from math import exp\n",
    "from math import log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data...\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "def parseData(fname):\n",
    "  for l in urlopen(fname):\n",
    "    yield eval(l)\n",
    "\n",
    "print(\"Reading data...\")\n",
    "data = list(parseData(\"http://jmcauley.ucsd.edu/cse190/data/beer/beer_50000.json\"))\n",
    "print(\"done\")\n",
    "\n",
    "def feature(datum):\n",
    "  feat = [1, datum['review/taste'], datum['review/appearance'], datum['review/aroma'], datum['review/palate'], datum['review/overall']]\n",
    "  return feat\n",
    "\n",
    "X = [feature(d) for d in data]\n",
    "y = [d['beer/ABV'] >= 6.5 for d in data]\n",
    "\n",
    "def inner(x,y):\n",
    "  return sum([x[i]*y[i] for i in range(len(x))])\n",
    "\n",
    "def sigmoid(x):\n",
    "  return 1.0 / (1 + exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##################################################\n",
    "# Logistic regression by gradient ascent         #\n",
    "##################################################\n",
    "\n",
    "# NEGATIVE Log-likelihood\n",
    "def f(theta, X, y, lam):\n",
    "  loglikelihood = 0\n",
    "  for i in range(len(X)):\n",
    "    logit = inner(X[i], theta)\n",
    "    loglikelihood -= log(1 + exp(-logit))\n",
    "    if not y[i]:\n",
    "      loglikelihood -= logit\n",
    "  for k in range(len(theta)):\n",
    "    loglikelihood -= lam * theta[k]*theta[k]\n",
    "  # for debugging\n",
    "  # print(\"ll =\" + str(loglikelihood))\n",
    "  return -loglikelihood\n",
    "\n",
    "# NEGATIVE Derivative of log-likelihood\n",
    "def fprime(theta, X, y, lam):\n",
    "  dl = [0]*len(theta)\n",
    "  for i in range(len(X)):\n",
    "    logit = inner(X[i], theta)\n",
    "    for k in range(len(theta)):\n",
    "      dl[k] += X[i][k] * (1 - sigmoid(logit))\n",
    "      if not y[i]:\n",
    "        dl[k] -= X[i][k]\n",
    "  for k in range(len(theta)):\n",
    "    dl[k] -= lam*2*theta[k]\n",
    "  return numpy.array([-x for x in dl])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = X\n",
    "y_train = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shuffled:  (50000, 6)\n",
      "y shuffled:  (50000,)\n",
      "x train:  (16667, 6) x validate:  (16666, 6) x test:  (16665, 6)\n",
      "y train:  (16667,) y validate:  (16666,) y test:  (16665,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# split into 1/3 train, 1/3 validation, 1/3 test\n",
    "\n",
    "Z = list(zip(X, y))\n",
    "\n",
    "random.shuffle(Z)\n",
    "\n",
    "x_shuffled, y_shuffled = zip(*Z)\n",
    "\n",
    "print(\"X shuffled: \", np.shape(x_shuffled))\n",
    "print(\"y shuffled: \", np.shape(y_shuffled))\n",
    "\n",
    "samples = len(x_shuffled)\n",
    "\n",
    "X_train = x_shuffled[0:round(samples/3)];\n",
    "y_train = y_shuffled[0:round(samples/3)];\n",
    "\n",
    "X_validation = x_shuffled[round(samples/3) + 1: 2 * round(samples/3)]\n",
    "y_validation = y_shuffled[round(samples/3) + 1: 2 * round(samples/3)]\n",
    "\n",
    "X_test = x_shuffled[2 * round(samples/3) + 1:samples]\n",
    "y_test = y_shuffled[2 * round(samples/3) + 1:samples]\n",
    "\n",
    "print(\"x train: \", np.shape(X_train), \"x validate: \", np.shape(X_validate), \"x test: \", np.shape(X_test))\n",
    "print(\"y train: \", np.shape(y_train), \"y validate: \", np.shape(y_validate), \"y test: \", np.shape(y_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##################################################\n",
    "# Train                                          #\n",
    "##################################################\n",
    "\n",
    "def train(lam):\n",
    "  theta,_,_ = scipy.optimize.fmin_l_bfgs_b(f, [0]*len(X[0]), fprime, pgtol = 10, args = (X_train, y_train, lam))\n",
    "  return theta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##################################################\n",
    "# Predict                                        #\n",
    "##################################################\n",
    "\n",
    "def performance(theta, X, y):\n",
    "  scores = [inner(theta,x) for x in X]\n",
    "  predictions = [s > 0 for s in scores]\n",
    "    \n",
    "  print(\"Samples: \", len(X), \"\\n\");\n",
    "  print(\"Positives: \", sum(predictions))\n",
    "  print(\"Negatives: \", len(predictions) - sum(predictions), \"\\n\")\n",
    "    \n",
    "  correct = [(a==b) for (a,b) in zip(predictions, y)]\n",
    "    \n",
    "  truePositive = sum(correct)\n",
    "  trueNegative = len(correct) - sum(correct)\n",
    "  print(\"True Positives: \", truePositive)\n",
    "  print(\"True Positives: \", trueNegative, \"\\n\")\n",
    "    \n",
    "  falsePositive = sum([(a==1 and b==0) for (a,b) in zip(predictions,y_train)])\n",
    "  falseNegative = sum([(a==0 and b==1) for (a,b) in zip(predictions,y_train)])\n",
    " \n",
    "  print(\"False Positives: \", falsePositive)\n",
    "  print(\"False Negatives: \", falseNegative, \"\\n\")\n",
    " \n",
    "  acc = sum(correct) * 1.0 / len(correct)\n",
    "  return acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################\n",
    "# Validation pipeline                            #\n",
    "##################################################\n",
    "lam = 1.0\n",
    "theta = train(lam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Training Set \n",
      "\n",
      "Samples:  16667 \n",
      "\n",
      "Positives:  12407\n",
      "Negatives:  4260 \n",
      "\n",
      "True Positives:  11924\n",
      "True Positives:  4743 \n",
      "\n",
      "False Positives:  3358\n",
      "False Negatives:  1385 \n",
      "\n",
      "lambda = 1.0:\taccuracy=0.7154256914861703 \n",
      "\n",
      "==================================================\n",
      "Validation Set \n",
      "\n",
      "Samples:  16666 \n",
      "\n",
      "Positives:  12336\n",
      "Negatives:  4330 \n",
      "\n",
      "True Positives:  12009\n",
      "True Positives:  4657 \n",
      "\n",
      "False Positives:  4679\n",
      "False Negatives:  2776 \n",
      "\n",
      "lambda = 1.0:\taccuracy=0.7205688227529101 \n",
      "\n",
      "==================================================\n",
      "Testing Set \n",
      "\n",
      "Samples:  16665 \n",
      "\n",
      "Positives:  12225\n",
      "Negatives:  4440 \n",
      "\n",
      "True Positives:  12014\n",
      "True Positives:  4651 \n",
      "\n",
      "False Positives:  4593\n",
      "False Negatives:  2800 \n",
      "\n",
      "lambda = 1.0:\taccuracy=0.7209120912091209 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "labels  = [\"Training Set\", \"Validation Set\", \"Testing Set\"]\n",
    "corpusX = [X_train, X_validation, X_test]\n",
    "corpusY = [y_train, y_validation, y_test]\n",
    "\n",
    "for (label, x, y) in zip(labels, corpusX, corpusY):\n",
    "    print(\"==================================================\")\n",
    "    print(label, \"\\n\")\n",
    "    acc = performance(theta, x, y)\n",
    "    print(\"lambda = \" + str(lam) + \":\\taccuracy=\" + str(acc), \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Testing Set \n",
      "\n",
      "Samples:  16667 \n",
      "\n",
      "Positives:  12481\n",
      "Negatives:  4186 \n",
      "\n",
      "True Positives:  11922\n",
      "True Positives:  4745 \n",
      "\n",
      "False Positives:  3396\n",
      "False Negatives:  1349 \n",
      "\n",
      "lambda = 0:\taccuracy=0.7153056938861223 \n",
      "\n",
      "==================================================\n",
      "Testing Set \n",
      "\n",
      "Samples:  16666 \n",
      "\n",
      "Positives:  12423\n",
      "Negatives:  4243 \n",
      "\n",
      "True Positives:  11976\n",
      "True Positives:  4690 \n",
      "\n",
      "False Positives:  4710\n",
      "False Negatives:  2720 \n",
      "\n",
      "lambda = 0:\taccuracy=0.718588743549742 \n",
      "\n",
      "==================================================\n",
      "Testing Set \n",
      "\n",
      "Samples:  16665 \n",
      "\n",
      "Positives:  12321\n",
      "Negatives:  4344 \n",
      "\n",
      "True Positives:  11956\n",
      "True Positives:  4709 \n",
      "\n",
      "False Positives:  4641\n",
      "False Negatives:  2752 \n",
      "\n",
      "lambda = 0:\taccuracy=0.7174317431743175 \n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "==================================================\n",
      "Testing Set \n",
      "\n",
      "Samples:  16667 \n",
      "\n",
      "Positives:  12482\n",
      "Negatives:  4185 \n",
      "\n",
      "True Positives:  11921\n",
      "True Positives:  4746 \n",
      "\n",
      "False Positives:  3397\n",
      "False Negatives:  1349 \n",
      "\n",
      "lambda = 0.01:\taccuracy=0.7152456950860983 \n",
      "\n",
      "==================================================\n",
      "Testing Set \n",
      "\n",
      "Samples:  16666 \n",
      "\n",
      "Positives:  12422\n",
      "Negatives:  4244 \n",
      "\n",
      "True Positives:  11979\n",
      "True Positives:  4687 \n",
      "\n",
      "False Positives:  4711\n",
      "False Negatives:  2722 \n",
      "\n",
      "lambda = 0.01:\taccuracy=0.71876875075003 \n",
      "\n",
      "==================================================\n",
      "Testing Set \n",
      "\n",
      "Samples:  16665 \n",
      "\n",
      "Positives:  12323\n",
      "Negatives:  4342 \n",
      "\n",
      "True Positives:  11958\n",
      "True Positives:  4707 \n",
      "\n",
      "False Positives:  4642\n",
      "False Negatives:  2751 \n",
      "\n",
      "lambda = 0.01:\taccuracy=0.7175517551755175 \n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "==================================================\n",
      "Testing Set \n",
      "\n",
      "Samples:  16667 \n",
      "\n",
      "Positives:  12486\n",
      "Negatives:  4181 \n",
      "\n",
      "True Positives:  11919\n",
      "True Positives:  4748 \n",
      "\n",
      "False Positives:  3400\n",
      "False Negatives:  1348 \n",
      "\n",
      "lambda = 0.1:\taccuracy=0.7151256974860503 \n",
      "\n",
      "==================================================\n",
      "Testing Set \n",
      "\n",
      "Samples:  16666 \n",
      "\n",
      "Positives:  12426\n",
      "Negatives:  4240 \n",
      "\n",
      "True Positives:  11979\n",
      "True Positives:  4687 \n",
      "\n",
      "False Positives:  4711\n",
      "False Negatives:  2718 \n",
      "\n",
      "lambda = 0.1:\taccuracy=0.71876875075003 \n",
      "\n",
      "==================================================\n",
      "Testing Set \n",
      "\n",
      "Samples:  16665 \n",
      "\n",
      "Positives:  12321\n",
      "Negatives:  4344 \n",
      "\n",
      "True Positives:  11954\n",
      "True Positives:  4711 \n",
      "\n",
      "False Positives:  4641\n",
      "False Negatives:  2752 \n",
      "\n",
      "lambda = 0.1:\taccuracy=0.7173117311731173 \n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "==================================================\n",
      "Testing Set \n",
      "\n",
      "Samples:  16667 \n",
      "\n",
      "Positives:  12568\n",
      "Negatives:  4099 \n",
      "\n",
      "True Positives:  11903\n",
      "True Positives:  4764 \n",
      "\n",
      "False Positives:  3449\n",
      "False Negatives:  1315 \n",
      "\n",
      "lambda = 1:\taccuracy=0.7141657166856663 \n",
      "\n",
      "==================================================\n",
      "Testing Set \n",
      "\n",
      "Samples:  16666 \n",
      "\n",
      "Positives:  12513\n",
      "Negatives:  4153 \n",
      "\n",
      "True Positives:  11974\n",
      "True Positives:  4692 \n",
      "\n",
      "False Positives:  4747\n",
      "False Negatives:  2667 \n",
      "\n",
      "lambda = 1:\taccuracy=0.71846873874955 \n",
      "\n",
      "==================================================\n",
      "Testing Set \n",
      "\n",
      "Samples:  16665 \n",
      "\n",
      "Positives:  12408\n",
      "Negatives:  4257 \n",
      "\n",
      "True Positives:  11949\n",
      "True Positives:  4716 \n",
      "\n",
      "False Positives:  4672\n",
      "False Negatives:  2696 \n",
      "\n",
      "lambda = 1:\taccuracy=0.717011701170117 \n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "==================================================\n",
      "Testing Set \n",
      "\n",
      "Samples:  16667 \n",
      "\n",
      "Positives:  15099\n",
      "Negatives:  1568 \n",
      "\n",
      "True Positives:  11190\n",
      "True Positives:  5477 \n",
      "\n",
      "False Positives:  5071\n",
      "False Negatives:  406 \n",
      "\n",
      "lambda = 100:\taccuracy=0.6713865722685546 \n",
      "\n",
      "==================================================\n",
      "Testing Set \n",
      "\n",
      "Samples:  16666 \n",
      "\n",
      "Positives:  15094\n",
      "Negatives:  1572 \n",
      "\n",
      "True Positives:  11171\n",
      "True Positives:  5495 \n",
      "\n",
      "False Positives:  5658\n",
      "False Negatives:  997 \n",
      "\n",
      "lambda = 100:\taccuracy=0.6702868114724589 \n",
      "\n",
      "==================================================\n",
      "Testing Set \n",
      "\n",
      "Samples:  16665 \n",
      "\n",
      "Positives:  15018\n",
      "Negatives:  1647 \n",
      "\n",
      "True Positives:  11091\n",
      "True Positives:  5574 \n",
      "\n",
      "False Positives:  5605\n",
      "False Negatives:  1019 \n",
      "\n",
      "lambda = 100:\taccuracy=0.6655265526552655 \n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n"
     ]
    }
   ],
   "source": [
    "lambdas = [0, 0.01, 0.1, 1, 100]\n",
    "labels  = [\"Training Set\", \"Validation Set\", \"Testing Set\"]\n",
    "corpusX = [X_train, X_validation, X_test]\n",
    "corpusY = [y_train, y_validation, y_test]\n",
    "\n",
    "for lam in lambdas:\n",
    "    theta = train(lam)\n",
    "    for (x, y) in zip(corpusX, corpusY):\n",
    "        print(\"==================================================\")\n",
    "        print(label, \"\\n\")\n",
    "        acc = performance(theta, x, y)\n",
    "        print(\"lambda = \" + str(lam) + \":\\taccuracy=\" + str(acc), \"\\n\")\n",
    "    print(\"~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\")\n",
    "    print(\"~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\\n\")\n",
    "    \n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
