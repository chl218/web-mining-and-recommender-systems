{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from urllib.request import urlopen\n",
    "import scipy.optimize\n",
    "import random\n",
    "from math import exp\n",
    "from math import log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data...\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "def parseData(fname):\n",
    "  for l in urlopen(fname):\n",
    "    yield eval(l)\n",
    "\n",
    "print(\"Reading data...\")\n",
    "data = list(parseData(\"http://jmcauley.ucsd.edu/cse190/data/beer/beer_50000.json\"))\n",
    "print(\"done\")\n",
    "\n",
    "def feature(datum):\n",
    "  feat = [1, datum['review/taste'], datum['review/appearance'], datum['review/aroma'], datum['review/palate'], datum['review/overall']]\n",
    "  return feat\n",
    "\n",
    "X = [feature(d) for d in data]\n",
    "y = [d['beer/ABV'] >= 6.5 for d in data]\n",
    "\n",
    "def inner(x,y):\n",
    "  return sum([x[i]*y[i] for i in range(len(x))])\n",
    "\n",
    "def sigmoid(x):\n",
    "  return 1.0 / (1 + exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##################################################\n",
    "# Logistic regression by gradient ascent         #\n",
    "##################################################\n",
    "\n",
    "# NEGATIVE Log-likelihood\n",
    "def f(theta, X, y, lam):\n",
    "  loglikelihood = 0\n",
    "  for i in range(len(X)):\n",
    "    logit = inner(X[i], theta)\n",
    "    loglikelihood -= log(1 + exp(-logit))\n",
    "    if not y[i]:\n",
    "      loglikelihood -= (1.05*logit)\n",
    "  for k in range(len(theta)):\n",
    "    loglikelihood -= lam * theta[k]*theta[k]\n",
    "  # for debugging\n",
    "  # print(\"ll =\" + str(loglikelihood))\n",
    "  return -loglikelihood\n",
    "\n",
    "# NEGATIVE Derivative of log-likelihood\n",
    "def fprime(theta, X, y, lam):\n",
    "  dl = [0]*len(theta)\n",
    "  for i in range(len(X)):\n",
    "    logit = inner(X[i], theta)\n",
    "    for k in range(len(theta)):\n",
    "      dl[k] += X[i][k] * (1 - sigmoid(logit))\n",
    "      if not y[i]:\n",
    "        dl[k] -= X[i][k]\n",
    "  for k in range(len(theta)):\n",
    "    dl[k] -= lam*2*theta[k]\n",
    "  return np.array([-x for x in dl])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = X\n",
    "y_train = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shuffled:  (50000, 6)\n",
      "y shuffled:  (50000,)\n",
      "x train:  (16667, 6) x validate:  (16666, 6) x test:  (16665, 6)\n",
      "y train:  (16667,) y validate:  (16666,) y test:  (16665,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# split into 1/3 train, 1/3 validation, 1/3 test\n",
    "\n",
    "Z = list(zip(X, y))\n",
    "\n",
    "random.shuffle(Z)\n",
    "\n",
    "x_shuffled, y_shuffled = zip(*Z)\n",
    "\n",
    "print(\"X shuffled: \", np.shape(x_shuffled))\n",
    "print(\"y shuffled: \", np.shape(y_shuffled))\n",
    "\n",
    "samples = len(x_shuffled)\n",
    "\n",
    "X_train = x_shuffled[0:round(samples/3)];\n",
    "y_train = y_shuffled[0:round(samples/3)];\n",
    "\n",
    "X_validation = x_shuffled[round(samples/3) + 1: 2 * round(samples/3)]\n",
    "y_validation = y_shuffled[round(samples/3) + 1: 2 * round(samples/3)]\n",
    "\n",
    "X_test = x_shuffled[2 * round(samples/3) + 1:samples]\n",
    "y_test = y_shuffled[2 * round(samples/3) + 1:samples]\n",
    "\n",
    "print(\"x train: \", np.shape(X_train), \"x validate: \", np.shape(X_validation), \"x test: \", np.shape(X_test))\n",
    "print(\"y train: \", np.shape(y_train), \"y validate: \", np.shape(y_validation), \"y test: \", np.shape(y_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##################################################\n",
    "# Train                                          #\n",
    "##################################################\n",
    "\n",
    "def train(lam):\n",
    "  theta,_,_ = scipy.optimize.fmin_l_bfgs_b(f, [0]*len(X[0]), fprime, pgtol = 10, args = (X_train, y_train, lam))\n",
    "  return theta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##################################################\n",
    "# Predict                                        #\n",
    "##################################################\n",
    "\n",
    "def performance(theta, X, y):\n",
    "  scores = [inner(theta,x) for x in X]\n",
    "  predictions = [s > 0 for s in scores]\n",
    "    \n",
    "  positives = sum(predictions)\n",
    "  negatives = len(predictions) - sum(predictions)\n",
    "    \n",
    "  correct = [(a==b) for (a,b) in zip(predictions, y)]\n",
    "    \n",
    "  truePositives = sum(correct)\n",
    "  trueNegatives = len(correct) - sum(correct)\n",
    "\n",
    "  falsePositives = sum([(a==1 and b==0) for (a,b) in zip(predictions,y)])\n",
    "  falseNegatives = sum([(a==0 and b==1) for (a,b) in zip(predictions,y)])\n",
    " \n",
    "  acc = sum(correct) * 1.0 / len(correct)\n",
    "  return acc, positives, negatives, truePositives, trueNegatives, falsePositives, falseNegatives\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################\n",
    "# Validation pipeline                            #\n",
    "##################################################\n",
    "lam = 1.0\n",
    "theta = train(lam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Training Set \n",
      "\n",
      "Positives:  13670\n",
      "Negatives:  2997 \n",
      "\n",
      "True Positives:  11200\n",
      "True Positives:  5467 \n",
      "\n",
      "False Positives:  4369\n",
      "False Negatives:  1098 \n",
      "\n",
      "lambda = 1.0:\taccuracy=0.6719865602687947 \n",
      "\n",
      "==================================================\n",
      "Validation Set \n",
      "\n",
      "Positives:  13639\n",
      "Negatives:  3027 \n",
      "\n",
      "True Positives:  11379\n",
      "True Positives:  5287 \n",
      "\n",
      "False Positives:  4302\n",
      "False Negatives:  985 \n",
      "\n",
      "lambda = 1.0:\taccuracy=0.6827673106924277 \n",
      "\n",
      "==================================================\n",
      "Testing Set \n",
      "\n",
      "Positives:  13669\n",
      "Negatives:  2996 \n",
      "\n",
      "True Positives:  11377\n",
      "True Positives:  5288 \n",
      "\n",
      "False Positives:  4255\n",
      "False Negatives:  1033 \n",
      "\n",
      "lambda = 1.0:\taccuracy=0.6826882688268827 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "labels  = [\"Training Set\", \"Validation Set\", \"Testing Set\"]\n",
    "corpusX = [X_train, X_validation, X_test]\n",
    "corpusY = [y_train, y_validation, y_test]\n",
    "\n",
    "for (label, x, y) in zip(labels, corpusX, corpusY):\n",
    "    print(\"==================================================\")\n",
    "    print(label, \"\\n\")\n",
    "    acc, positives, negatives, truePositives, trueNegatives, falsePositives, falseNegatives = performance(theta, x, y)\n",
    "    \n",
    "    print(\"Positives: \", positives)\n",
    "    print(\"Negatives: \", negatives, \"\\n\")\n",
    "\n",
    "    print(\"True Positives: \", truePositives)\n",
    "    print(\"True Positives: \", trueNegatives, \"\\n\")\n",
    "    \n",
    "    print(\"False Positives: \", falsePositives)\n",
    "    print(\"False Negatives: \", falseNegatives, \"\\n\")\n",
    "    \n",
    "    print(\"lambda = \" + str(lam) + \":\\taccuracy=\" + str(acc), \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Training Set \n",
      "\n",
      "Positives:  13670\n",
      "Negatives:  2997 \n",
      "\n",
      "True Positives:  11200\n",
      "True Positives:  5467 \n",
      "\n",
      "False Positives:  4369\n",
      "False Negatives:  1098 \n",
      "\n",
      "lambda = 1.0:\taccuracy=0.6719865602687947 \n",
      "\n",
      "==================================================\n",
      "Validation Set \n",
      "\n",
      "Positives:  13639\n",
      "Negatives:  3027 \n",
      "\n",
      "True Positives:  11379\n",
      "True Positives:  5287 \n",
      "\n",
      "False Positives:  4302\n",
      "False Negatives:  985 \n",
      "\n",
      "lambda = 1.0:\taccuracy=0.6827673106924277 \n",
      "\n",
      "==================================================\n",
      "Testing Set \n",
      "\n",
      "Positives:  13669\n",
      "Negatives:  2996 \n",
      "\n",
      "True Positives:  11377\n",
      "True Positives:  5288 \n",
      "\n",
      "False Positives:  4255\n",
      "False Negatives:  1033 \n",
      "\n",
      "lambda = 1.0:\taccuracy=0.6826882688268827 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for (label, x, y) in zip(labels, corpusX, corpusY):\n",
    "    print(\"==================================================\")\n",
    "    print(label, \"\\n\")\n",
    "    acc, positives, negatives, truePositives, trueNegatives, falsePositives, falseNegatives = performance(theta, x, y)\n",
    "    \n",
    "    print(\"Positives: \", positives)\n",
    "    print(\"Negatives: \", negatives, \"\\n\")\n",
    "\n",
    "    print(\"True Positives: \", truePositives)\n",
    "    print(\"True Positives: \", trueNegatives, \"\\n\")\n",
    "    \n",
    "    print(\"False Positives: \", falsePositives)\n",
    "    print(\"False Negatives: \", falseNegatives, \"\\n\")\n",
    "    \n",
    "    print(\"lambda = \" + str(lam) + \":\\taccuracy=\" + str(acc), \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lambdas = [0, 0.01, 0.1, 1, 100]\n",
    "labels  = [\"Training Set\", \"Validation Set\", \"Testing Set\"]\n",
    "corpusX = [X_train, X_validation, X_test]\n",
    "corpusY = [y_train, y_validation, y_test]\n",
    "\n",
    "acc = []\n",
    "positives = []\n",
    "negatives = []\n",
    "truePositives = []\n",
    "trueNegatives = []\n",
    "falsePositives = []\n",
    "falseNegatives = []\n",
    "\n",
    "for lam in lambdas:\n",
    "    theta = train(lam)\n",
    "    for (x, y) in zip(corpusX, corpusY):\n",
    "        _acc, _positives, _negatives, _truePositives, _trueNegatives, _falsePositives, _falseNegatives \\\n",
    "            = performance(theta, x, y)\n",
    "            \n",
    "        acc.append(_acc)\n",
    "        positives.append(_positives)\n",
    "        negatives.append(_negatives)\n",
    "        truePositives.append(_truePositives)\n",
    "        trueNegatives.append(_trueNegatives)\n",
    "        falsePositives.append(_falsePositives)\n",
    "        falseNegatives.append(_falseNegatives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lambdas:         0.000 0.000 0.000 0.010 0.010 0.010 0.100 0.100 0.100 1.000 1.000 1.000 100.000 100.000 100.000 \n",
      "Accuracy:        0.671 0.683 0.682 0.671 0.683 0.682 0.671 0.683 0.682 0.672 0.683 0.683 0.663 0.667 0.674 \n",
      "\n",
      "Positives:       13632 13617 13640 13632 13617 13640 13635 13617 13642 13670 13639 13669 14904 14852 14892 \n",
      "Negatives:        3035  3049  3025  3035  3049  3025  3032  3049  3023  2997  3027  2996  1763  1814  1773 \n",
      "\n",
      "True Positives:  11190 11383 11372 11190 11383 11372 11191 11383 11370 11200 11379 11377 11048 11110 11226 \n",
      "True Negatives:   5477  5283  5293  5477  5283  5293  5476  5283  5295  5467  5287  5288  5619  5556  5439 \n",
      "\n",
      "False Positives:  4355  4289  4243  4355  4289  4243  4356  4289  4245  4369  4302  4255  5062  5043  4942 \n",
      "False Negatives:  1122   994  1050  1122   994  1050  1120   994  1050  1098   985  1033   557   513   497 "
     ]
    }
   ],
   "source": [
    "print(\"Lambdas:         \", end='') \n",
    "[print(\"%.3f \" % val, end='') for val in np.repeat(lambdas,3)]\n",
    "print(\"\\nAccuracy:        \", end='') \n",
    "[print(\"%.3f \" % val, end='') for val in acc]\n",
    "\n",
    "print(\"\\n\\nPositives:       \", end='') \n",
    "[print(\"%5d \" % val, end='') for val in positives]\n",
    "print(\"\\nNegatives:       \", end='') \n",
    "[print(\"%5d \" % val, end='') for val in negatives]\n",
    "\n",
    "print(\"\\n\\nTrue Positives:  \", end='') \n",
    "[print(\"%5d \" % val, end='') for val in truePositives]\n",
    "print(\"\\nTrue Negatives:  \", end='') \n",
    "[print(\"%5d \" % val, end='') for val in trueNegatives]\n",
    "\n",
    "print(\"\\n\\nFalse Positives: \", end='') \n",
    "[print(\"%5d \" % val, end='') for val in falsePositives]\n",
    "print(\"\\nFalse Negatives: \", end='') \n",
    "[print(\"%5d \" % val, end='') for val in falseNegatives];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Network visualization ###\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = set()\n",
    "nodes = set()\n",
    "for edge in urlopen(\"http://jmcauley.ucsd.edu/cse255/data/facebook/egonet.txt\"):\n",
    "  x,y = edge.split()\n",
    "  x,y = int(x),int(y)\n",
    "  edges.add((x,y))\n",
    "  edges.add((y,x))\n",
    "  nodes.add(x)\n",
    "  nodes.add(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeEAAAFCCAYAAADGwmVOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "G = nx.Graph()\n",
    "for e in edges:\n",
    "  G.add_edge(e[0],e[1])\n",
    "nx.draw(G)\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Connected Components:  3\n",
      "Largest Connected Component: 40\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of Connected Components: \", nx.number_connected_components(G))\n",
    "print(\"Largest Connected Component:\", max([len(x) for x in nx.connected_components(G)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low IDs:   [697, 703, 708, 713, 719, 729, 745, 747, 753, 769, 772, 774, 798, 800, 803, 804, 805, 810, 811, 819]\n",
      "High IDs:  [823, 825, 828, 830, 840, 856, 861, 863, 864, 869, 876, 878, 880, 882, 884, 886, 888, 889, 890, 893]\n"
     ]
    }
   ],
   "source": [
    "largest_cc = sorted(max(nx.connected_components(G), key=len))\n",
    "\n",
    "half = round(len(largest_cc)/2)\n",
    "\n",
    "split_lo = largest_cc[:half]\n",
    "split_hi = largest_cc[half:]\n",
    "\n",
    "print(\"Low IDs:  \", split_lo)\n",
    "print(\"High IDs: \", split_hi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EdgeDataView([(769, 890), (769, 856), (769, 697), (769, 774), (769, 869), (769, 811), (769, 828), (769, 753), (769, 798), (769, 800), (769, 747), (769, 708)])"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def makeGraph(lst):\n",
    "    edges = set()\n",
    "    nodes = set()\n",
    "    for (node, _) in lst:\n",
    "      x,y = edge.split()\n",
    "      x,y = int(x),int(y)\n",
    "      edges.add((x,y))\n",
    "      edges.add((y,x))\n",
    "      nodes.add(x)\n",
    "      nodes.add(y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
