{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from urllib.request import urlopen\n",
    "import scipy.optimize\n",
    "import random\n",
    "from math import exp\n",
    "from math import log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data...\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "def parseData(fname):\n",
    "  for l in urlopen(fname):\n",
    "    yield eval(l)\n",
    "\n",
    "print(\"Reading data...\")\n",
    "data = list(parseData(\"http://jmcauley.ucsd.edu/cse190/data/beer/beer_50000.json\"))\n",
    "print(\"done\")\n",
    "\n",
    "def feature(datum):\n",
    "  feat = [1, datum['review/taste'], datum['review/appearance'], datum['review/aroma'], datum['review/palate'], datum['review/overall']]\n",
    "  return feat\n",
    "\n",
    "X = [feature(d) for d in data]\n",
    "y = [d['beer/ABV'] >= 6.5 for d in data]\n",
    "\n",
    "def inner(x,y):\n",
    "  return sum([x[i]*y[i] for i in range(len(x))])\n",
    "\n",
    "def sigmoid(x):\n",
    "  return 1.0 / (1 + exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##################################################\n",
    "# Logistic regression by gradient ascent         #\n",
    "##################################################\n",
    "\n",
    "# NEGATIVE Log-likelihood\n",
    "def f(theta, X, y, lam):\n",
    "  loglikelihood = 0\n",
    "  for i in range(len(X)):\n",
    "    logit = inner(X[i], theta)\n",
    "    loglikelihood -= log(1 + exp(-logit))\n",
    "    if not y[i]:\n",
    "      loglikelihood -= (1.05*logit)\n",
    "  for k in range(len(theta)):\n",
    "    loglikelihood -= lam * theta[k]*theta[k]\n",
    "  # for debugging\n",
    "  # print(\"ll =\" + str(loglikelihood))\n",
    "  return -loglikelihood\n",
    "\n",
    "# NEGATIVE Derivative of log-likelihood\n",
    "def fprime(theta, X, y, lam):\n",
    "  dl = [0]*len(theta)\n",
    "  for i in range(len(X)):\n",
    "    logit = inner(X[i], theta)\n",
    "    for k in range(len(theta)):\n",
    "      dl[k] += X[i][k] * (1 - sigmoid(logit))\n",
    "      if not y[i]:\n",
    "        dl[k] -= X[i][k]\n",
    "  for k in range(len(theta)):\n",
    "    dl[k] -= lam*2*theta[k]\n",
    "  return np.array([-x for x in dl])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = X\n",
    "y_train = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shuffled:  (50000, 6)\n",
      "y shuffled:  (50000,)\n",
      "x train:  (16667, 6) x validate:  (16666, 6) x test:  (16665, 6)\n",
      "y train:  (16667,) y validate:  (16666,) y test:  (16665,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# split into 1/3 train, 1/3 validation, 1/3 test\n",
    "\n",
    "Z = list(zip(X, y))\n",
    "\n",
    "random.shuffle(Z)\n",
    "\n",
    "x_shuffled, y_shuffled = zip(*Z)\n",
    "\n",
    "print(\"X shuffled: \", np.shape(x_shuffled))\n",
    "print(\"y shuffled: \", np.shape(y_shuffled))\n",
    "\n",
    "samples = len(x_shuffled)\n",
    "\n",
    "X_train = x_shuffled[0:round(samples/3)];\n",
    "y_train = y_shuffled[0:round(samples/3)];\n",
    "\n",
    "X_validation = x_shuffled[round(samples/3) + 1: 2 * round(samples/3)]\n",
    "y_validation = y_shuffled[round(samples/3) + 1: 2 * round(samples/3)]\n",
    "\n",
    "X_test = x_shuffled[2 * round(samples/3) + 1:samples]\n",
    "y_test = y_shuffled[2 * round(samples/3) + 1:samples]\n",
    "\n",
    "print(\"x train: \", np.shape(X_train), \"x validate: \", np.shape(X_validation), \"x test: \", np.shape(X_test))\n",
    "print(\"y train: \", np.shape(y_train), \"y validate: \", np.shape(y_validation), \"y test: \", np.shape(y_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##################################################\n",
    "# Train                                          #\n",
    "##################################################\n",
    "\n",
    "def train(lam):\n",
    "  theta,_,_ = scipy.optimize.fmin_l_bfgs_b(f, [0]*len(X[0]), fprime, pgtol = 10, args = (X_train, y_train, lam))\n",
    "  return theta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##################################################\n",
    "# Predict                                        #\n",
    "##################################################\n",
    "\n",
    "def performance(theta, X, y):\n",
    "  scores = [inner(theta,x) for x in X]\n",
    "  predictions = [s > 0 for s in scores]\n",
    "    \n",
    "  positives = sum(predictions)\n",
    "  negatives = len(predictions) - sum(predictions)\n",
    "    \n",
    "  correct = [(a==b) for (a,b) in zip(predictions, y)]\n",
    "    \n",
    "  truePositives = sum(correct)\n",
    "  trueNegatives = len(correct) - sum(correct)\n",
    "\n",
    "  falsePositives = sum([(a==1 and b==0) for (a,b) in zip(predictions,y)])\n",
    "  falseNegatives = sum([(a==0 and b==1) for (a,b) in zip(predictions,y)])\n",
    " \n",
    "  acc = sum(correct) * 1.0 / len(correct)\n",
    "  return acc, positives, negatives, truePositives, trueNegatives, falsePositives, falseNegatives\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##################################################\n",
    "# Validation pipeline                            #\n",
    "##################################################\n",
    "lam = 1.0\n",
    "theta = train(lam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Training Set \n",
      "\n",
      "Positives:  13214\n",
      "Negatives:  3453 \n",
      "\n",
      "True Positives:  11265\n",
      "True Positives:  5402 \n",
      "\n",
      "False Positives:  4161\n",
      "False Negatives:  1241 \n",
      "\n",
      "lambda = 1.0:\taccuracy=0.6758864822703546 \n",
      "\n",
      "==================================================\n",
      "Validation Set \n",
      "\n",
      "Positives:  13274\n",
      "Negatives:  3392 \n",
      "\n",
      "True Positives:  11220\n",
      "True Positives:  5446 \n",
      "\n",
      "False Positives:  4169\n",
      "False Negatives:  1277 \n",
      "\n",
      "lambda = 1.0:\taccuracy=0.6732269290771631 \n",
      "\n",
      "==================================================\n",
      "Testing Set \n",
      "\n",
      "Positives:  13279\n",
      "Negatives:  3386 \n",
      "\n",
      "True Positives:  11397\n",
      "True Positives:  5268 \n",
      "\n",
      "False Positives:  4028\n",
      "False Negatives:  1240 \n",
      "\n",
      "lambda = 1.0:\taccuracy=0.6838883888388839 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "labels  = [\"Training Set\", \"Validation Set\", \"Testing Set\"]\n",
    "corpusX = [X_train, X_validation, X_test]\n",
    "corpusY = [y_train, y_validation, y_test]\n",
    "\n",
    "for (label, x, y) in zip(labels, corpusX, corpusY):\n",
    "    print(\"==================================================\")\n",
    "    print(label, \"\\n\")\n",
    "    acc, positives, negatives, truePositives, trueNegatives, falsePositives, falseNegatives = performance(theta, x, y)\n",
    "    \n",
    "    print(\"Positives: \", positives)\n",
    "    print(\"Negatives: \", negatives, \"\\n\")\n",
    "\n",
    "    print(\"True Positives: \", truePositives)\n",
    "    print(\"True Positives: \", trueNegatives, \"\\n\")\n",
    "    \n",
    "    print(\"False Positives: \", falsePositives)\n",
    "    print(\"False Negatives: \", falseNegatives, \"\\n\")\n",
    "    \n",
    "    print(\"lambda = \" + str(lam) + \":\\taccuracy=\" + str(acc), \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Training Set \n",
      "\n",
      "Positives:  13214\n",
      "Negatives:  3453 \n",
      "\n",
      "True Positives:  11265\n",
      "True Positives:  5402 \n",
      "\n",
      "False Positives:  4161\n",
      "False Negatives:  1241 \n",
      "\n",
      "lambda = 1.0:\taccuracy=0.6758864822703546 \n",
      "\n",
      "==================================================\n",
      "Validation Set \n",
      "\n",
      "Positives:  13274\n",
      "Negatives:  3392 \n",
      "\n",
      "True Positives:  11220\n",
      "True Positives:  5446 \n",
      "\n",
      "False Positives:  4169\n",
      "False Negatives:  1277 \n",
      "\n",
      "lambda = 1.0:\taccuracy=0.6732269290771631 \n",
      "\n",
      "==================================================\n",
      "Testing Set \n",
      "\n",
      "Positives:  13279\n",
      "Negatives:  3386 \n",
      "\n",
      "True Positives:  11397\n",
      "True Positives:  5268 \n",
      "\n",
      "False Positives:  4028\n",
      "False Negatives:  1240 \n",
      "\n",
      "lambda = 1.0:\taccuracy=0.6838883888388839 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for (label, x, y) in zip(labels, corpusX, corpusY):\n",
    "    print(\"==================================================\")\n",
    "    print(label, \"\\n\")\n",
    "    acc, positives, negatives, truePositives, trueNegatives, falsePositives, falseNegatives = performance(theta, x, y)\n",
    "    \n",
    "    print(\"Positives: \", positives)\n",
    "    print(\"Negatives: \", negatives, \"\\n\")\n",
    "\n",
    "    print(\"True Positives: \", truePositives)\n",
    "    print(\"True Positives: \", trueNegatives, \"\\n\")\n",
    "    \n",
    "    print(\"False Positives: \", falsePositives)\n",
    "    print(\"False Negatives: \", falseNegatives, \"\\n\")\n",
    "    \n",
    "    print(\"lambda = \" + str(lam) + \":\\taccuracy=\" + str(acc), \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lambdas = [0, 0.01, 0.1, 1, 100]\n",
    "labels  = [\"Training Set\", \"Validation Set\", \"Testing Set\"]\n",
    "corpusX = [X_train, X_validation, X_test]\n",
    "corpusY = [y_train, y_validation, y_test]\n",
    "\n",
    "acc = []\n",
    "positives = []\n",
    "negatives = []\n",
    "truePositives = []\n",
    "trueNegatives = []\n",
    "falsePositives = []\n",
    "falseNegatives = []\n",
    "\n",
    "for lam in lambdas:\n",
    "    theta = train(lam)\n",
    "    for (x, y) in zip(corpusX, corpusY):\n",
    "        _acc, _positives, _negatives, _truePositives, _trueNegatives, _falsePositives, _falseNegatives \\\n",
    "            = performance(theta, x, y)\n",
    "            \n",
    "        acc.append(_acc)\n",
    "        positives.append(_positives)\n",
    "        negatives.append(_negatives)\n",
    "        truePositives.append(_truePositives)\n",
    "        trueNegatives.append(_trueNegatives)\n",
    "        falsePositives.append(_falsePositives)\n",
    "        falseNegatives.append(_falseNegatives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lambdas:         0.000 0.000 0.000 0.010 0.010 0.010 0.100 0.100 0.100 1.000 1.000 1.000 100.000 100.000 100.000 \n",
      "Accuracy:        0.676 0.674 0.684 0.676 0.674 0.684 0.676 0.674 0.684 0.676 0.673 0.684 0.667 0.667 0.677 \n",
      "\n",
      "Positives:       13196 13249 13260 13196 13249 13260 13196 13249 13260 13214 13274 13279 14728 14719 14744 \n",
      "Negatives:        3471  3417  3405  3471  3417  3405  3471  3417  3405  3453  3392  3386  1939  1947  1921 \n",
      "\n",
      "True Positives:  11275 11231 11404 11275 11231 11404 11275 11231 11404 11265 11220 11397 11125 11109 11274 \n",
      "True Negatives:   5392  5435  5261  5392  5435  5261  5392  5435  5261  5402  5446  5268  5542  5557  5391 \n",
      "\n",
      "False Positives:  4147  4151  4015  4147  4151  4015  4147  4151  4015  4161  4169  4028  4988  4947  4822 \n",
      "False Negatives:  1245  1284  1246  1245  1284  1246  1245  1284  1246  1241  1277  1240   554   610   569 "
     ]
    }
   ],
   "source": [
    "print(\"Lambdas:         \", end='') \n",
    "[print(\"%.3f \" % val, end='') for val in np.repeat(lambdas,3)]\n",
    "print(\"\\nAccuracy:        \", end='') \n",
    "[print(\"%.3f \" % val, end='') for val in acc]\n",
    "\n",
    "print(\"\\n\\nPositives:       \", end='') \n",
    "[print(\"%5d \" % val, end='') for val in positives]\n",
    "print(\"\\nNegatives:       \", end='') \n",
    "[print(\"%5d \" % val, end='') for val in negatives]\n",
    "\n",
    "print(\"\\n\\nTrue Positives:  \", end='') \n",
    "[print(\"%5d \" % val, end='') for val in truePositives]\n",
    "print(\"\\nTrue Negatives:  \", end='') \n",
    "[print(\"%5d \" % val, end='') for val in trueNegatives]\n",
    "\n",
    "print(\"\\n\\nFalse Positives: \", end='') \n",
    "[print(\"%5d \" % val, end='') for val in falsePositives]\n",
    "print(\"\\nFalse Negatives: \", end='') \n",
    "[print(\"%5d \" % val, end='') for val in falseNegatives];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Network visualization ###\n",
    "import networkx as nx\n",
    "from networkx.algorithms.community import greedy_modularity_communities\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = set()\n",
    "nodes = set()\n",
    "for edge in urlopen(\"http://jmcauley.ucsd.edu/cse255/data/facebook/egonet.txt\"):\n",
    "  x,y = edge.split()\n",
    "  x,y = int(x),int(y)\n",
    "  edges.add((x,y))\n",
    "  edges.add((y,x))\n",
    "  nodes.add(x)\n",
    "  nodes.add(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeEAAAFCCAYAAADGwmVOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "G = nx.Graph()\n",
    "for e in edges:\n",
    "  G.add_edge(e[0],e[1])\n",
    "nx.draw(G)\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Connected Components:  3\n",
      "Largest Connected Component: 40\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of Connected Components: \", nx.number_connected_components(G))\n",
    "print(\"Largest Connected Component:\", max([len(x) for x in nx.connected_components(G)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low IDs:   [697, 703, 708, 713, 719, 729, 745, 747, 753, 769, 772, 774, 798, 800, 803, 804, 805, 810, 811, 819]\n",
      "High IDs:  [823, 825, 828, 830, 840, 856, 861, 863, 864, 869, 876, 878, 880, 882, 884, 886, 888, 889, 890, 893]\n",
      "Normalized Cut Cost:  0.4224058769513316\n"
     ]
    }
   ],
   "source": [
    "largest_cc = sorted(max(nx.connected_components(G), key=len))\n",
    "\n",
    "half = round(len(largest_cc)/2)\n",
    "\n",
    "split_lo = largest_cc[:half]\n",
    "split_hi = largest_cc[half:]\n",
    "\n",
    "print(\"Low IDs:  \", split_lo)\n",
    "print(\"High IDs: \", split_hi)\n",
    "print(\"Normalized Cut Cost: \", (1/2)*nx.normalized_cut_size(G, split_lo, split_hi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of Iterations:  3\n",
      "New Low IDs:   [697, 703, 708, 713, 719, 745, 747, 753, 769, 772, 774, 798, 800, 803, 805, 810, 811, 819, 823, 828, 830, 840, 856, 869, 880, 890]\n",
      "New High IDs:  [729, 804, 825, 861, 863, 864, 876, 878, 882, 884, 886, 888, 889, 893]\n",
      "Normalized Cut Cost:  0.09817045961624274\n"
     ]
    }
   ],
   "source": [
    "largest_cc = sorted(max(nx.connected_components(G), key=len))\n",
    "\n",
    "half = round(len(largest_cc)/2)\n",
    "\n",
    "split_lo = largest_cc[:half]\n",
    "split_hi = largest_cc[half:]\n",
    "\n",
    "prevCost = 0;\n",
    "currCost = (1/2)*nx.normalized_cut_size(G, split_lo, split_hi)\n",
    "\n",
    "iter = 0\n",
    "while prevCost != currCost:\n",
    "    iter += 1\n",
    "    prevCost = currCost\n",
    "    lo = [i for i in split_lo] # deep copy\n",
    "    hi = [i for i in split_hi] # deep copy\n",
    "    \n",
    "    # move lo to hi if cut cost is lower\n",
    "    for val in split_lo:          \n",
    "        lo.remove(val)\n",
    "        hi.append(val)\n",
    "        newCost = (1/2)*nx.normalized_cut_size(G, lo, hi)\n",
    "        \n",
    "        if(newCost > currCost): # not lower, restore\n",
    "            lo.append(val)\n",
    "            hi.remove(val)\n",
    "        else:\n",
    "            currCost = newCost # update current cost\n",
    "\n",
    "    # move hi to lo if cut cost is lower\n",
    "    for val in split_hi:\n",
    "        lo.append(val)\n",
    "        hi.remove(val)\n",
    "        newCost = (1/2)*nx.normalized_cut_size(G, lo, hi)\n",
    "        \n",
    "        if(newCost > currCost): # not lower, restore\n",
    "            lo.remove(val)\n",
    "            hi.append(val)\n",
    "        else:\n",
    "            currCost = newCost # update current cost\n",
    "           \n",
    "    split_lo = [i for i in lo] # deep copy\n",
    "    split_hi = [i for i in hi] # deep copy\n",
    "    \n",
    "print(\"\\nNumber of Iterations: \", iter)\n",
    "print(\"New Low IDs:  \", sorted(split_lo))\n",
    "print(\"New High IDs: \", sorted(split_hi))\n",
    "print(\"Normalized Cut Cost: \", (1/2)*nx.normalized_cut_size(G, split_lo, split_hi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Community Size:       40\n",
      "Max Modularity Size:  19 \n",
      "\n",
      "Largest Community:    [697, 703, 708, 713, 719, 729, 745, 747, 753, 769, 772, 774, 798, 800, 803, 804, 805, 810, 811, 819, 823, 825, 828, 830, 840, 856, 861, 863, 864, 869, 876, 878, 880, 882, 884, 886, 888, 889, 890, 893]\n",
      "Max Modularity Size:  [697, 703, 708, 713, 719, 745, 747, 772, 774, 800, 803, 805, 810, 819, 823, 828, 830, 840, 880]\n"
     ]
    }
   ],
   "source": [
    "# find max modularity of all cc\n",
    "# idx\n",
    "max_modularity = list(greedy_modularity_communities(G))\n",
    "\n",
    "print(\"Community Size:      \", len(largest_cc))\n",
    "print(\"Max Modularity Size: \", len(max_modularity[0]), \"\\n\")\n",
    "\n",
    "print(\"Largest Community:   \", largest_cc)\n",
    "print(\"Max Modularity Size: \", sorted(max_modularity[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
