{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from urllib.request import urlopen\n",
    "import scipy.optimize\n",
    "import random\n",
    "from math import exp\n",
    "from math import log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data...\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "def parseData(fname):\n",
    "  for l in urlopen(fname):\n",
    "    yield eval(l)\n",
    "\n",
    "print(\"Reading data...\")\n",
    "data = list(parseData(\"http://jmcauley.ucsd.edu/cse190/data/beer/beer_50000.json\"))\n",
    "print(\"done\")\n",
    "\n",
    "def feature(datum):\n",
    "  feat = [1, datum['review/taste'], datum['review/appearance'], datum['review/aroma'], datum['review/palate'], datum['review/overall']]\n",
    "  return feat\n",
    "\n",
    "X = [feature(d) for d in data]\n",
    "y = [d['beer/ABV'] >= 6.5 for d in data]\n",
    "\n",
    "def inner(x,y):\n",
    "  return sum([x[i]*y[i] for i in range(len(x))])\n",
    "\n",
    "def sigmoid(x):\n",
    "  return 1.0 / (1 + exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################\n",
    "# Logistic regression by gradient ascent         #\n",
    "##################################################\n",
    "\n",
    "# NEGATIVE Log-likelihood\n",
    "def f(theta, X, y, lam):\n",
    "  loglikelihood = 0\n",
    "  for i in range(len(X)):\n",
    "    logit = inner(X[i], theta)\n",
    "    loglikelihood -= log(1 + exp(-logit))\n",
    "    if not y[i]:\n",
    "      loglikelihood -= (1.05*logit)\n",
    "  for k in range(len(theta)):\n",
    "    loglikelihood -= lam * theta[k]*theta[k]\n",
    "  # for debugging\n",
    "  # print(\"ll =\" + str(loglikelihood))\n",
    "  return -loglikelihood\n",
    "\n",
    "# NEGATIVE Derivative of log-likelihood\n",
    "def fprime(theta, X, y, lam):\n",
    "  dl = [0]*len(theta)\n",
    "  for i in range(len(X)):\n",
    "    logit = inner(X[i], theta)\n",
    "    for k in range(len(theta)):\n",
    "      dl[k] += X[i][k] * (1 - sigmoid(logit))\n",
    "      if not y[i]:\n",
    "        dl[k] -= X[i][k]\n",
    "  for k in range(len(theta)):\n",
    "    dl[k] -= lam*2*theta[k]\n",
    "  return numpy.array([-x for x in dl])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = X\n",
    "y_train = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shuffled:  (50000, 6)\n",
      "y shuffled:  (50000,)\n",
      "x train:  (16667, 6) x validate:  (16666, 6) x test:  (16665, 6)\n",
      "y train:  (16667,) y validate:  (16666,) y test:  (16665,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# split into 1/3 train, 1/3 validation, 1/3 test\n",
    "\n",
    "Z = list(zip(X, y))\n",
    "\n",
    "random.shuffle(Z)\n",
    "\n",
    "x_shuffled, y_shuffled = zip(*Z)\n",
    "\n",
    "print(\"X shuffled: \", np.shape(x_shuffled))\n",
    "print(\"y shuffled: \", np.shape(y_shuffled))\n",
    "\n",
    "samples = len(x_shuffled)\n",
    "\n",
    "X_train = x_shuffled[0:round(samples/3)];\n",
    "y_train = y_shuffled[0:round(samples/3)];\n",
    "\n",
    "X_validation = x_shuffled[round(samples/3) + 1: 2 * round(samples/3)]\n",
    "y_validation = y_shuffled[round(samples/3) + 1: 2 * round(samples/3)]\n",
    "\n",
    "X_test = x_shuffled[2 * round(samples/3) + 1:samples]\n",
    "y_test = y_shuffled[2 * round(samples/3) + 1:samples]\n",
    "\n",
    "print(\"x train: \", np.shape(X_train), \"x validate: \", np.shape(X_validate), \"x test: \", np.shape(X_test))\n",
    "print(\"y train: \", np.shape(y_train), \"y validate: \", np.shape(y_validate), \"y test: \", np.shape(y_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##################################################\n",
    "# Train                                          #\n",
    "##################################################\n",
    "\n",
    "def train(lam):\n",
    "  theta,_,_ = scipy.optimize.fmin_l_bfgs_b(f, [0]*len(X[0]), fprime, pgtol = 10, args = (X_train, y_train, lam))\n",
    "  return theta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##################################################\n",
    "# Predict                                        #\n",
    "##################################################\n",
    "\n",
    "def performance(theta, X, y):\n",
    "  scores = [inner(theta,x) for x in X]\n",
    "  predictions = [s > 0 for s in scores]\n",
    "    \n",
    "  positives = sum(predictions)\n",
    "  negatives = len(predictions) - sum(predictions)\n",
    "    \n",
    "  correct = [(a==b) for (a,b) in zip(predictions, y)]\n",
    "    \n",
    "  truePositives = sum(correct)\n",
    "  trueNegatives = len(correct) - sum(correct)\n",
    "\n",
    "  falsePositives = sum([(a==1 and b==0) for (a,b) in zip(predictions,y)])\n",
    "  falseNegatives = sum([(a==0 and b==1) for (a,b) in zip(predictions,y)])\n",
    " \n",
    "  acc = sum(correct) * 1.0 / len(correct)\n",
    "  return acc, positives, negatives, truePositives, trueNegatives, falsePositives, falseNegatives\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################\n",
    "# Validation pipeline                            #\n",
    "##################################################\n",
    "lam = 1.0\n",
    "theta = train(lam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Training Set \n",
      "\n",
      "Samples:  16667 \n",
      "\n",
      "Positives:  12568\n",
      "Negatives:  4099 \n",
      "\n",
      "True Positives:  11903\n",
      "True Positives:  4764 \n",
      "\n",
      "False Positives:  3449\n",
      "False Negatives:  1315 \n",
      "\n",
      "lambda = 1.0:\taccuracy=0.7141657166856663 \n",
      "\n",
      "==================================================\n",
      "Validation Set \n",
      "\n",
      "Samples:  16666 \n",
      "\n",
      "Positives:  12513\n",
      "Negatives:  4153 \n",
      "\n",
      "True Positives:  11974\n",
      "True Positives:  4692 \n",
      "\n",
      "False Positives:  3396\n",
      "False Negatives:  1296 \n",
      "\n",
      "lambda = 1.0:\taccuracy=0.71846873874955 \n",
      "\n",
      "==================================================\n",
      "Testing Set \n",
      "\n",
      "Samples:  16665 \n",
      "\n",
      "Positives:  12408\n",
      "Negatives:  4257 \n",
      "\n",
      "True Positives:  11949\n",
      "True Positives:  4716 \n",
      "\n",
      "False Positives:  3402\n",
      "False Negatives:  1314 \n",
      "\n",
      "lambda = 1.0:\taccuracy=0.717011701170117 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "labels  = [\"Training Set\", \"Validation Set\", \"Testing Set\"]\n",
    "corpusX = [X_train, X_validation, X_test]\n",
    "corpusY = [y_train, y_validation, y_test]\n",
    "\n",
    "for (label, x, y) in zip(labels, corpusX, corpusY):\n",
    "    print(\"==================================================\")\n",
    "    print(label, \"\\n\")\n",
    "    acc, positives, negatives, truePositives, trueNegatives, falsePositives, falseNegatives = performance(theta, x, y)\n",
    "    \n",
    "    print(\"Positives: \", positives)\n",
    "    print(\"Negatives: \", negatives, \"\\n\")\n",
    "\n",
    "    print(\"True Positives: \", truePositives)\n",
    "    print(\"True Positives: \", trueNegatives, \"\\n\")\n",
    "    \n",
    "    print(\"False Positives: \", falsePositives)\n",
    "    print(\"False Negatives: \", falseNegatives, \"\\n\")\n",
    "    \n",
    "    print(\"lambda = \" + str(lam) + \":\\taccuracy=\" + str(acc), \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Training Set \n",
      "\n",
      "Positives:  13624\n",
      "Negatives:  3043 \n",
      "\n",
      "True Positives:  11289\n",
      "True Positives:  5378 \n",
      "\n",
      "False Positives:  4284\n",
      "False Negatives:  1094 \n",
      "\n",
      "lambda = 1.0:\taccuracy=0.6773264534709306 \n",
      "\n",
      "==================================================\n",
      "Validation Set \n",
      "\n",
      "Positives:  13722\n",
      "Negatives:  2944 \n",
      "\n",
      "True Positives:  11273\n",
      "True Positives:  5393 \n",
      "\n",
      "False Positives:  4351\n",
      "False Negatives:  1042 \n",
      "\n",
      "lambda = 1.0:\taccuracy=0.6764070562822513 \n",
      "\n",
      "==================================================\n",
      "Testing Set \n",
      "\n",
      "Positives:  13559\n",
      "Negatives:  3106 \n",
      "\n",
      "True Positives:  11302\n",
      "True Positives:  5363 \n",
      "\n",
      "False Positives:  4301\n",
      "False Negatives:  1062 \n",
      "\n",
      "lambda = 1.0:\taccuracy=0.6781878187818782 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for (label, x, y) in zip(labels, corpusX, corpusY):\n",
    "    print(\"==================================================\")\n",
    "    print(label, \"\\n\")\n",
    "    acc, positives, negatives, truePositives, trueNegatives, falsePositives, falseNegatives = performance(theta, x, y)\n",
    "    \n",
    "    print(\"Positives: \", positives)\n",
    "    print(\"Negatives: \", negatives, \"\\n\")\n",
    "\n",
    "    print(\"True Positives: \", truePositives)\n",
    "    print(\"True Positives: \", trueNegatives, \"\\n\")\n",
    "    \n",
    "    print(\"False Positives: \", falsePositives)\n",
    "    print(\"False Negatives: \", falseNegatives, \"\\n\")\n",
    "    \n",
    "    print(\"lambda = \" + str(lam) + \":\\taccuracy=\" + str(acc), \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambdas = [0, 0.01, 0.1, 1, 100]\n",
    "labels  = [\"Training Set\", \"Validation Set\", \"Testing Set\"]\n",
    "corpusX = [X_train, X_validation, X_test]\n",
    "corpusY = [y_train, y_validation, y_test]\n",
    "\n",
    "acc = []\n",
    "positives = []\n",
    "negatives = []\n",
    "truePositives = []\n",
    "trueNegatives = []\n",
    "falsePositives = []\n",
    "falseNegatives = []\n",
    "\n",
    "for lam in lambdas:\n",
    "    theta = train(lam)\n",
    "    for (x, y) in zip(corpusX, corpusY):\n",
    "        _acc, _positives, _negatives, _truePositives, _trueNegatives, _falsePositives, _falseNegatives \\\n",
    "            = performance(theta, x, y)\n",
    "            \n",
    "        acc.append(_acc)\n",
    "        positives.append(_positives)\n",
    "        negatives.append(_negatives)\n",
    "        truePositives.append(_truePositives)\n",
    "        trueNegatives.append(_trueNegatives)\n",
    "        falsePositives.append(_falsePositives)\n",
    "        falseNegatives.append(_falseNegatives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambads:  [0, 0.01, 0.1, 1, 100]\n",
      "accuracy:  ['0.7153', '0.7186', '0.7174', '0.7152', '0.7188', '0.7176', '0.7151', '0.7188', '0.7173', '0.7142', '0.7185', '0.7170', '0.6714', '0.6703', '0.6655'] \n",
      "\n",
      "positives:  [12481, 12423, 12321, 12482, 12422, 12323, 12486, 12426, 12321, 12568, 12513, 12408, 15099, 15094, 15018]\n",
      "negatives:  [4186, 4243, 4344, 4185, 4244, 4342, 4181, 4240, 4344, 4099, 4153, 4257, 1568, 1572, 1647] \n",
      "\n",
      "true positives:  [11922, 11976, 11956, 11921, 11979, 11958, 11919, 11979, 11954, 11903, 11974, 11949, 11190, 11171, 11091]\n",
      "true negatives:  [4745, 4690, 4709, 4746, 4687, 4707, 4748, 4687, 4711, 4764, 4692, 4716, 5477, 5495, 5574] \n",
      "\n",
      "false positives:  [3396, 3350, 3355, 3397, 3348, 3355, 3400, 3350, 3356, 3449, 3396, 3402, 5071, 5088, 5136]\n",
      "false negatives:  [1349, 1340, 1354, 1349, 1339, 1352, 1348, 1337, 1355, 1315, 1296, 1314, 406, 407, 438]\n"
     ]
    }
   ],
   "source": [
    "_acc = [\"%.4f\" % a for a in acc]\n",
    "\n",
    "print(\"lambads: \", lambdas)\n",
    "print(\"accuracy: \", _acc, \"\\n\")\n",
    "\n",
    "print(\"positives: \", positives)\n",
    "print(\"negatives: \", negatives, \"\\n\")\n",
    "\n",
    "print(\"true positives: \", truePositives)\n",
    "print(\"true negatives: \", trueNegatives, \"\\n\")\n",
    "\n",
    "print(\"false positives: \", falsePositives)\n",
    "print(\"false negatives: \", falseNegatives,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
