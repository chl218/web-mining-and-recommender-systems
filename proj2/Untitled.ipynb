{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from urllib.request import urlopen\n",
    "import scipy.optimize\n",
    "import random\n",
    "from math import exp\n",
    "from math import log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data...\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "def parseData(fname):\n",
    "  for l in urlopen(fname):\n",
    "    yield eval(l)\n",
    "\n",
    "print(\"Reading data...\")\n",
    "data = list(parseData(\"http://jmcauley.ucsd.edu/cse190/data/beer/beer_50000.json\"))\n",
    "print(\"done\")\n",
    "\n",
    "def feature(datum):\n",
    "  feat = [1, datum['review/taste'], datum['review/appearance'], datum['review/aroma'], datum['review/palate'], datum['review/overall']]\n",
    "  return feat\n",
    "\n",
    "X = [feature(d) for d in data]\n",
    "y = [d['beer/ABV'] >= 6.5 for d in data]\n",
    "\n",
    "def inner(x,y):\n",
    "  return sum([x[i]*y[i] for i in range(len(x))])\n",
    "\n",
    "def sigmoid(x):\n",
    "  return 1.0 / (1 + exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##################################################\n",
    "# Logistic regression by gradient ascent         #\n",
    "##################################################\n",
    "\n",
    "# NEGATIVE Log-likelihood\n",
    "def f(theta, X, y, lam):\n",
    "  loglikelihood = 0\n",
    "  for i in range(len(X)):\n",
    "    logit = inner(X[i], theta)\n",
    "    loglikelihood -= log(1 + exp(-logit))\n",
    "    if not y[i]:\n",
    "      loglikelihood -= logit\n",
    "  for k in range(len(theta)):\n",
    "    loglikelihood -= lam * theta[k]*theta[k]\n",
    "  # for debugging\n",
    "  # print(\"ll =\" + str(loglikelihood))\n",
    "  return -loglikelihood\n",
    "\n",
    "# NEGATIVE Derivative of log-likelihood\n",
    "def fprime(theta, X, y, lam):\n",
    "  dl = [0]*len(theta)\n",
    "  for i in range(len(X)):\n",
    "    logit = inner(X[i], theta)\n",
    "    for k in range(len(theta)):\n",
    "      dl[k] += X[i][k] * (1 - sigmoid(logit))\n",
    "      if not y[i]:\n",
    "        dl[k] -= X[i][k]\n",
    "  for k in range(len(theta)):\n",
    "    dl[k] -= lam*2*theta[k]\n",
    "  return numpy.array([-x for x in dl])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = X\n",
    "y_train = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shuffled:  (50000, 6)\n",
      "y shuffled:  (50000,)\n",
      "x train:  (16667, 6) x validate:  (16666, 6) x test:  (16665, 6)\n",
      "y train:  (16667,) y validate:  (16666,) y test:  (16665,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# \n",
    "Z = list(zip(X, y))\n",
    "\n",
    "random.shuffle(Z)\n",
    "\n",
    "x_shuffled, y_shuffled = zip(*Z)\n",
    "\n",
    "print(\"X shuffled: \", np.shape(x_shuffled))\n",
    "print(\"y shuffled: \", np.shape(y_shuffled))\n",
    "\n",
    "samples = len(x_shuffled)\n",
    "\n",
    "X_train = x_shuffled[0:round(samples/3)];\n",
    "y_train = y_shuffled[0:round(samples/3)];\n",
    "\n",
    "X_validation = x_shuffled[round(samples/3) + 1: 2 * round(samples/3)]\n",
    "y_validation = y_shuffled[round(samples/3) + 1: 2 * round(samples/3)]\n",
    "\n",
    "X_test = x_shuffled[2 * round(samples/3) + 1:samples]\n",
    "y_test = y_shuffled[2 * round(samples/3) + 1:samples]\n",
    "\n",
    "print(\"x train: \", np.shape(X_train), \"x validate: \", np.shape(X_validate), \"x test: \", np.shape(X_test))\n",
    "print(\"y train: \", np.shape(y_train), \"y validate: \", np.shape(y_validate), \"y test: \", np.shape(y_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##################################################\n",
    "# Train                                          #\n",
    "##################################################\n",
    "\n",
    "def train(lam):\n",
    "  theta,_,_ = scipy.optimize.fmin_l_bfgs_b(f, [0]*len(X[0]), fprime, pgtol = 10, args = (X_train, y_train, lam))\n",
    "  return theta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##################################################\n",
    "# Predict                                        #\n",
    "##################################################\n",
    "\n",
    "def performance(theta, X, y):\n",
    "  scores = [inner(theta,x) for x in X]\n",
    "  predictions = [s > 0 for s in scores]\n",
    "    \n",
    "  print(\"Samples: \", len(X), \"\\n\");\n",
    "  print(\"Positives: \", sum(predictions))\n",
    "  print(\"Negatives: \", len(predictions) - sum(predictions), \"\\n\")\n",
    "    \n",
    "  correct = [(a==b) for (a,b) in zip(predictions, y)]\n",
    "    \n",
    "  truePositive = sum(correct)\n",
    "  trueNegative = len(correct) - sum(correct)\n",
    "  print(\"True Positives: \", truePositive)\n",
    "  print(\"True Positives: \", trueNegative, \"\\n\")\n",
    "    \n",
    "  falsePositive = sum([(a==1 and b==0) for (a,b) in zip(predictions,y_train)])\n",
    "  falseNegative = sum([(a==0 and b==1) for (a,b) in zip(predictions,y_train)])\n",
    " \n",
    "  print(\"False Positives: \", falsePositive)\n",
    "  print(\"False Negatives: \", falseNegative, \"\\n\")\n",
    " \n",
    "  acc = sum(correct) * 1.0 / len(correct)\n",
    "  return acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################\n",
    "# Validation pipeline                            #\n",
    "##################################################\n",
    "lam = 1.0\n",
    "theta = train(lam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples:  16667 \n",
      "\n",
      "Positives:  12304\n",
      "Negatives:  4363 \n",
      "\n",
      "True Positives:  11973\n",
      "True Positives:  4694 \n",
      "\n",
      "False Positives:  3317\n",
      "False Negatives:  1377 \n",
      "\n",
      "lambda = 1.0:\taccuracy=0.7183656326873462\n"
     ]
    }
   ],
   "source": [
    "acc = performance(theta, X_train, y_train)\n",
    "print(\"lambda = \" + str(lam) + \":\\taccuracy=\" + str(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples:  16666 \n",
      "\n",
      "Positives:  12316\n",
      "Negatives:  4350 \n",
      "\n",
      "True Positives:  12037\n",
      "True Positives:  4629 \n",
      "\n",
      "False Positives:  4619\n",
      "False Negatives:  2703 \n",
      "\n",
      "lambda = 1.0:\taccuracy=0.7222488899555982\n"
     ]
    }
   ],
   "source": [
    "acc = performance(theta, X_validation, y_validation)\n",
    "print(\"lambda = \" + str(lam) + \":\\taccuracy=\" + str(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples:  16665 \n",
      "\n",
      "Positives:  12286\n",
      "Negatives:  4379 \n",
      "\n",
      "True Positives:  11991\n",
      "True Positives:  4674 \n",
      "\n",
      "False Positives:  4632\n",
      "False Negatives:  2745 \n",
      "\n",
      "lambda = 1.0:\taccuracy=0.7195319531953195\n"
     ]
    }
   ],
   "source": [
    "acc = performance(theta, X_test, y_test)\n",
    "print(\"lambda = \" + str(lam) + \":\\taccuracy=\" + str(acc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
